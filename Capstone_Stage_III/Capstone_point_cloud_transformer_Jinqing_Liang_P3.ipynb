{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_point_cloud_transformer_Jinqing_Liang_P3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOM5HX8efJd/gNkuAGz9W9y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greenteausa/DATA606_Capstone/blob/main/Capstone_Stage_III/Capstone_point_cloud_transformer_Jinqing_Liang_P3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzJTCWOY7rJS"
      },
      "source": [
        "## Import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uvb9tzSiGPK9",
        "outputId": "8ec633b6-902b-4d11-f8dd-8667b3920d7c"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "#import argparse\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import scipy.spatial.distance\n",
        "from torch.utils.data import DataLoader, Dataset \n",
        "\n",
        "import torchvision \n",
        "from torchvision import transforms, utils\n",
        "\n",
        "#from pointnet2_ops import pointnet2_utils\n",
        "import time \n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as nnf\n",
        "import glob\n",
        "import h5py\n",
        "#random.seed = 42\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "torch.backends.cudnn.deterministic=True\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFTcSETEuDg0"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O13hg-TprwYa"
      },
      "source": [
        "pointbiggerthan500df_train = pd.read_csv('/content/gdrive/MyDrive/Capstone_606/IntrA/generated/ad/train_df.csv')\n",
        "pointbiggerthan500df_test = pd.read_csv('/content/gdrive/MyDrive/Capstone_606/IntrA/generated/ad/test_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W-kbsnEUMnn"
      },
      "source": [
        "### Final Normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI2LAcMjUMA5"
      },
      "source": [
        "class Normalize(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "        \n",
        "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n",
        "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
        "\n",
        "        return  norm_pointcloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS1Tzc4wUBTE"
      },
      "source": [
        "### Sample points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8br9f9-T9Xm"
      },
      "source": [
        "class PointSampler(object):\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, int)\n",
        "        self.output_size = output_size\n",
        "    \n",
        "    def triangle_area(self, pt1, pt2, pt3):\n",
        "        side_a = np.linalg.norm(pt1 - pt2)\n",
        "        side_b = np.linalg.norm(pt2 - pt3)\n",
        "        side_c = np.linalg.norm(pt3 - pt1)\n",
        "        s = 0.5 * ( side_a + side_b + side_c)\n",
        "        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n",
        "\n",
        "    def sample_point(self, pt1, pt2, pt3):\n",
        "        # barycentric coordinates on a triangle\n",
        "        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
        "        s, t = sorted([random.random(), random.random()])\n",
        "        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n",
        "        return (f(0), f(1), f(2))\n",
        "        \n",
        "    \n",
        "    def __call__(self, point):\n",
        "        verts = point\n",
        "        verts = np.array(verts)\n",
        "        #areas = np.zeros((len(faces)))\n",
        "\n",
        "        #for i in range(len(areas)):\n",
        "        #    areas[i] = (self.triangle_area(verts[faces[i][0]],\n",
        "        #                                   verts[faces[i][1]],\n",
        "        #                                   verts[faces[i][2]]))\n",
        "            \n",
        "        #sampled_faces = (random.choices(faces, \n",
        "        #                              weights=areas,\n",
        "        #                              cum_weights=None,\n",
        "        #                              k=self.output_size))\n",
        "        \n",
        "        #sampled_points = np.zeros((self.output_size, 3))\n",
        "\n",
        "        #for i in range(len(sampled_faces)):\n",
        "        #    sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n",
        "        #                                           verts[sampled_faces[i][1]],\n",
        "        #                                           verts[sampled_faces[i][2]]))\n",
        "        \n",
        "        sampled_points = (random.choices(verts, \n",
        "                                      #weights=areas,\n",
        "                                      cum_weights=None,\n",
        "                                      k=self.output_size))\n",
        "        \n",
        "        return np.array(sampled_points)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zm4_2p_Vcw0"
      },
      "source": [
        "### Add random rotation of the whole pointcloud and random noise to its points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1fdVMa4VYSX"
      },
      "source": [
        "class RandRotation_z(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        theta = random.random() * 2. * math.pi\n",
        "        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
        "                               [ math.sin(theta),  math.cos(theta),    0],\n",
        "                               [0,                             0,      1]])\n",
        "        \n",
        "        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
        "        return  rot_pointcloud\n",
        "    \n",
        "class RandomNoise(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
        "    \n",
        "        noisy_pointcloud = pointcloud + noise\n",
        "        return  noisy_pointcloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x7xvkR7Uh2D"
      },
      "source": [
        "### ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9U2jPGxUdza"
      },
      "source": [
        "class ToTensor(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        return torch.from_numpy(pointcloud)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGBUPJlu8Hk6"
      },
      "source": [
        "### Default_transforms for validation and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPV8IPdSThWd"
      },
      "source": [
        "def default_transforms(): # for data augmentaiton.\n",
        "    return transforms.Compose([\n",
        "                                PointSampler(500),\n",
        "                                Normalize(),\n",
        "                                ToTensor()\n",
        "                              ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx1irv8L8TMI"
      },
      "source": [
        "### Transformation for train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDi0htsuhDfl"
      },
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                    PointSampler(500),\n",
        "                    Normalize(),\n",
        "                    RandRotation_z(),\n",
        "                    RandomNoise(),\n",
        "                    ToTensor()\n",
        "                    ]) # for data training."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VkQUxCz8fDP"
      },
      "source": [
        "### PointCloudDataBal(for data upsampling)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiEmaOXelrrM"
      },
      "source": [
        "class PointCloudDataBal(Dataset):\n",
        "    def __init__(self, df, valid=False, transform=default_transforms()):\n",
        "        \n",
        "        self.classes = {\"vessel\": 0, \"aneurysm\": 1}\n",
        "        self.transforms = transform if not valid else default_transforms()\n",
        "        self.valid = valid\n",
        "        #self.files = []\n",
        "        # create a new dataframe\n",
        "        self.files = df\n",
        "        self.files_train = self.files.sample(frac = 0.8)\n",
        "        #self.files_train = self.__balance_data(self.files_train)\n",
        "        self.files_valid = self.files.drop(self.files_train.index)\n",
        "        self.files_train = self.__balance_data(self.files_train)\n",
        "        self.files_valid = self.__balance_data(self.files_valid)\n",
        "\n",
        "    def __balance_data(self, data_table):\n",
        "        from sklearn.utils import resample\n",
        "        n_samples_major = len(data_table[data_table.classification=='vessel'])\n",
        "        df_majority = data_table[data_table.classification=='vessel']\n",
        "        df_minority = data_table[data_table.classification=='aneurysm']\n",
        "\n",
        "        # Upsample minority class\n",
        "        df_minority_upsampled = resample(df_minority, \n",
        "                                 replace=True,     # sample with replacement\n",
        "                                 n_samples=n_samples_major,    # to match majority class\n",
        "                                 random_state=42) # reproducible results\n",
        "        print(len(df_minority_upsampled))\n",
        "        # Combine majority class with upsampled minority class\n",
        "        df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
        "        return df_upsampled\n",
        "    \n",
        "    def __len__(self):\n",
        "        if self.valid == False:\n",
        "          return len(self.files_train)\n",
        "        else:\n",
        "          return len(self.files_valid)\n",
        "\n",
        "    def __load_ad_file(self, path):\n",
        "        points = []\n",
        "        labels = []\n",
        "        normals = []\n",
        "        #print(path)\n",
        "        with open(path, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                s_line = line.split()\n",
        "                points.append([float(s_line[0]), float(s_line[1]), float(s_line[2])])\n",
        "                normals.append([float(s_line[3]), float(s_line[4]), float(s_line[5])])\n",
        "                labels.append(int(s_line[6]))\n",
        "\n",
        "        return points, labels, normals\n",
        "\n",
        "    def __preproc__(self, file):\n",
        "        \"\"\"for preprocessing.\"\"\"\n",
        "        points, labels, normals = self.__load_ad_file(file)\n",
        "        points = np.array(points)\n",
        "        if self.transforms:\n",
        "            pointcloud = self.transforms(points)\n",
        "        return pointcloud\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.valid == False:\n",
        "          pcd_path = self.files_train.iloc[idx]['path'] # check if [idx] here is true for framework.\n",
        "          category = self.files_train.iloc[idx]['classification']\n",
        "        else:\n",
        "          #print(idx)\n",
        "          pcd_path = self.files_valid.iloc[idx]['path']\n",
        "          category = self.files_valid.iloc[idx]['classification']\n",
        "        \n",
        "        pointcloud = self.__preproc__(pcd_path)\n",
        "        return pointcloud, self.classes[category]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXShbj5l8yov"
      },
      "source": [
        "Check train and valid dataset size and put them to Dataloader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHjBkV4esDd-",
        "outputId": "43cac0a6-424e-4ecf-d275-734abc4397c0"
      },
      "source": [
        "train_ds = PointCloudDataBal(pointbiggerthan500df_train, transform=train_transforms)\n",
        "valid_ds = PointCloudDataBal(pointbiggerthan500df_train, valid=True, transform=default_transforms)#upscaled."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1094\n",
            "279\n",
            "1094\n",
            "279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kitWS99xwRLc"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True, drop_last=True)\n",
        "valid_loader = DataLoader(dataset=valid_ds, batch_size=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg0JMXmD0OEI"
      },
      "source": [
        "## Clone the library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um40P6ZE0NF8",
        "outputId": "d484f889-8194-4eeb-c0f6-7ae552c19f79"
      },
      "source": [
        "!git clone https://github.com/uyzhang/PCT_Pytorch.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PCT_Pytorch'...\n",
            "remote: Enumerating objects: 113, done.\u001b[K\n",
            "remote: Counting objects: 100% (113/113), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 113 (delta 41), reused 66 (delta 11), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (113/113), 10.24 MiB | 30.47 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQV5KtvTXlod",
        "outputId": "0e386946-9b8d-4f1c-a93e-7e25fc05cb25"
      },
      "source": [
        "!pip install PCT_Pytorch/pointnet2_ops_lib/. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./PCT_Pytorch/pointnet2_ops_lib\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pointnet2-ops==3.0.0) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pointnet2-ops==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pointnet2-ops==3.0.0) (1.19.5)\n",
            "Building wheels for collected packages: pointnet2-ops\n",
            "  Building wheel for pointnet2-ops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pointnet2-ops: filename=pointnet2_ops-3.0.0-cp37-cp37m-linux_x86_64.whl size=5420029 sha256=4600148657690c9ab1de3cad571966d4195a6620fc43bcdb5b8636e7ec85bcaa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-aw8vesl_/wheels/81/8e/37/f6ef9f8b3fee67c2c7fa79f19112b3d36b464506d2716f8dbc\n",
            "Successfully built pointnet2-ops\n",
            "Installing collected packages: pointnet2-ops\n",
            "Successfully installed pointnet2-ops-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx9H8S_RO14b"
      },
      "source": [
        "from pointnet2_ops import pointnet2_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJl-KEuFYHfY"
      },
      "source": [
        "### Cal_loss,square_distance, index_points, knn_point, sample_and_group"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ2A6YDaWOpG"
      },
      "source": [
        "# main.py \n",
        "#xp_name=train \n",
        "#num_points=1024 \n",
        "#use_sgd=True \n",
        "#batch_size 32 \n",
        "#epochs 250 \n",
        "#lr 0.0001\n",
        "\n",
        "def cal_loss(pred, gold, smoothing=True):\n",
        "    ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n",
        "     \n",
        "    gold = gold.contiguous().view(-1)  #gold is ground truth.\n",
        "\n",
        "    if smoothing:\n",
        "        eps = 0.2\n",
        "        n_class = pred.size(1)\n",
        "        #https://codesuche.com/python-examples/torch.zeros_like.scatter/\n",
        "        # Generate one-hot matrix: N x C.\n",
        "        # Only label position is 1 and all other positions are 0\n",
        "        # gold include -1 value (IGNORE_ID) and this will lead to assert error.\n",
        "        #Tensor.scatter_(dim, index, src, reduce=None) → Tensor\n",
        "        one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1) #https://pytorch.org/docs/master/generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_\n",
        "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
        "        log_prb = F.log_softmax(pred, dim=1)\n",
        "\n",
        "        loss = -(one_hot * log_prb).sum(dim=1).mean()\n",
        "    else:\n",
        "        loss = F.cross_entropy(pred, gold, reduction='mean')\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def square_distance(src, dst):\n",
        "    \"\"\"\n",
        "    Calculate Euclid distance between each two points(n,m).\n",
        "    src^T * dst = xn * xm + yn * ym + zn * zm；\n",
        "    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;\n",
        "    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;\n",
        "    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2\n",
        "         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst\n",
        "    Input:\n",
        "        src: source points, [B, N, C]\n",
        "        dst: target points, [B, M, C]\n",
        "    Output:\n",
        "        dist: per-point square distance, [B, N, M]\n",
        "    \"\"\"\n",
        "    B, N, _ = src.shape\n",
        "    _, M, _ = dst.shape\n",
        "    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1)) #https://pytorch.org/docs/stable/generated/torch.matmul.html\n",
        "    dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
        "    dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
        "    return dist #Actually it's Euclid distance**2.\n",
        "\n",
        "def index_points(points, idx):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        points: input points data, [B, N, C]\n",
        "        idx: sample index data, [B, S]\n",
        "    Return:\n",
        "        new_points:, indexed points data, [B, S, C]\n",
        "    \"\"\"\n",
        "    device = points.device\n",
        "    B = points.shape[0]\n",
        "    view_shape = list(idx.shape)\n",
        "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
        "    repeat_shape = list(idx.shape)\n",
        "    repeat_shape[0] = 1\n",
        "    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
        "    new_points = points[batch_indices, idx, :]\n",
        "    return new_points\n",
        "\n",
        "def knn_point(nsample, xyz, new_xyz):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        nsample: max sample number in local region\n",
        "        xyz: all points, [B, N, C]\n",
        "        new_xyz: query points, [B, S, C]\n",
        "    Return:\n",
        "        group_idx: grouped points index, [B, S, nsample]\n",
        "    \"\"\"\n",
        "    sqrdists = square_distance(new_xyz, xyz)\n",
        "    _, group_idx = torch.topk(sqrdists, nsample, dim = -1, largest=False, sorted=False)# https://pytorch.org/docs/stable/generated/torch.topk.html\n",
        "    return group_idx\n",
        "\n",
        "def sample_and_group(npoint, radius, nsample, xyz, points):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        npoint:\n",
        "        radius:\n",
        "        nsample:\n",
        "        xyz: input points position data, [B, N, 3]\n",
        "        points: input points data, [B, N, D]\n",
        "    Return:\n",
        "        new_xyz: sampled points position data, [B, npoint, nsample, 3]\n",
        "        new_points: sampled points data, [B, npoint, nsample, 3+D]\n",
        "    \"\"\"\n",
        "    B, N, C = xyz.shape\n",
        "    S = npoint \n",
        "    xyz =  xyz.contiguous() #make the xyz contiguous.\n",
        "    #fps (farthest point sampling)\n",
        "    fps_idx = pointnet2_utils.furthest_point_sample(xyz, npoint).long() # [B, npoint]\n",
        "    new_xyz = index_points(xyz, fps_idx) \n",
        "    new_points = index_points(points, fps_idx)\n",
        "    # new_xyz = xyz[:]\n",
        "    # new_points = points[:]\n",
        "\n",
        "    idx = knn_point(nsample, xyz, new_xyz)\n",
        "    #idx = query_ball_point(radius, nsample, xyz, new_xyz)\n",
        "    grouped_xyz = index_points(xyz, idx) # [B, npoint, nsample, C] #C mean xyz\n",
        "    grouped_xyz_norm = grouped_xyz - new_xyz.view(B, S, 1, C)\n",
        "    grouped_points = index_points(points, idx)\n",
        "    grouped_points_norm = grouped_points - new_points.view(B, S, 1, -1)\n",
        "    new_points = torch.cat([grouped_points_norm, new_points.view(B, S, 1, -1).repeat(1, 1, nsample, 1)], dim=-1)\n",
        "    return new_xyz, new_points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE_mdNiSV7LZ"
      },
      "source": [
        "### Model Definition: Local_op, Pct, Point_Transformer_Last, SA_Layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbtXe4WMV6sM"
      },
      "source": [
        "class Local_op(nn.Module):# get local features.\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Local_op, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, n, s, d = x.size()  # torch.Size([32, 512, 32, 6]) \n",
        "        x = x.permute(0, 1, 3, 2)    \n",
        "        x = x.reshape(-1, d, s)  \n",
        "        batch_size, _, N = x.size() #B, -, N\n",
        "        x = F.relu(self.bn1(self.conv1(x))) # B, D, N\n",
        "        x = F.relu(self.bn2(self.conv2(x))) # B, D, N\n",
        "        x = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\n",
        "        x = x.reshape(b, n, -1).permute(0, 2, 1) # \n",
        "        return x\n",
        "\n",
        "class Pct(nn.Module):\n",
        "    def __init__(self, output_channels=2):\n",
        "        super(Pct, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(3, 64, kernel_size=1, bias=False)\n",
        "        self.conv2 = nn.Conv1d(64, 64, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.gather_local_0 = Local_op(in_channels=128, out_channels=128)\n",
        "        self.gather_local_1 = Local_op(in_channels=256, out_channels=256)\n",
        "\n",
        "        self.pt_last = Point_Transformer_Last()\n",
        "\n",
        "        self.conv_fuse = nn.Sequential(nn.Conv1d(1280, 1024, kernel_size=1, bias=False),\n",
        "                                    nn.BatchNorm1d(1024),\n",
        "                                    nn.LeakyReLU(negative_slope=0.2))\n",
        "\n",
        "\n",
        "        self.linear1 = nn.Linear(1024, 512, bias=False)\n",
        "        self.bn6 = nn.BatchNorm1d(512)\n",
        "        self.dp1 = nn.Dropout(p=0.5)\n",
        "        self.linear2 = nn.Linear(512, 256)\n",
        "        self.bn7 = nn.BatchNorm1d(256)\n",
        "        self.dp2 = nn.Dropout(p=0.5)\n",
        "        self.linear3 = nn.Linear(256, output_channels)\n",
        "\n",
        "    def forward(self, x): # for training\n",
        "        xyz = x.permute(0, 2, 1)\n",
        "        batch_size, _, _ = x.size()\n",
        "        # B, D, N\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        # B, D, N\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        new_xyz, new_feature = sample_and_group(npoint=512, radius=0.15, nsample=32, xyz=xyz, points=x)         \n",
        "        feature_0 = self.gather_local_0(new_feature)\n",
        "        feature = feature_0.permute(0, 2, 1)#\n",
        "        new_xyz, new_feature = sample_and_group(npoint=256, radius=0.2, nsample=32, xyz=new_xyz, points=feature) \n",
        "        feature_1 = self.gather_local_1(new_feature)\n",
        "\n",
        "        x = self.pt_last(feature_1)\n",
        "        x = torch.cat([x, feature_1], dim=1)\n",
        "        x = self.conv_fuse(x)\n",
        "        x = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\n",
        "        x = F.leaky_relu(self.bn6(self.linear1(x)), negative_slope=0.2)\n",
        "        x = self.dp1(x)\n",
        "        x = F.leaky_relu(self.bn7(self.linear2(x)), negative_slope=0.2)\n",
        "        x = self.dp2(x)\n",
        "        x = self.linear3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Point_Transformer_Last(nn.Module): # Concat\n",
        "    def __init__(self, channels=256):\n",
        "    #def __init__(self, args, channels=256):\n",
        "        super(Point_Transformer_Last, self).__init__()\n",
        "        #self.args = args\n",
        "        self.conv1 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n",
        "        self.conv2 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(channels)\n",
        "        self.bn2 = nn.BatchNorm1d(channels)\n",
        "\n",
        "        self.sa1 = SA_Layer(channels)\n",
        "        self.sa2 = SA_Layer(channels)\n",
        "        self.sa3 = SA_Layer(channels)\n",
        "        self.sa4 = SA_Layer(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # b, 3, npoint, nsample  \n",
        "        # conv2d 3 -> 128 channels 1, 1\n",
        "        # b * npoint, c, nsample \n",
        "        # permute reshape\n",
        "        batch_size, _, N = x.size()\n",
        "\n",
        "        # B, D, N\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x1 = self.sa1(x)\n",
        "        x2 = self.sa2(x1)\n",
        "        x3 = self.sa3(x2)\n",
        "        x4 = self.sa4(x3)\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "\n",
        "        return x\n",
        "\n",
        "class SA_Layer(nn.Module): #Offset-Attension\n",
        "    def __init__(self, channels):\n",
        "        super(SA_Layer, self).__init__() \n",
        "        self.q_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n",
        "        self.k_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n",
        "        self.q_conv.weight = self.k_conv.weight\n",
        "        self.q_conv.bias = self.k_conv.bias\n",
        "\n",
        "        self.v_conv = nn.Conv1d(channels, channels, 1)\n",
        "        self.trans_conv = nn.Conv1d(channels, channels, 1)\n",
        "        self.after_norm = nn.BatchNorm1d(channels)\n",
        "        self.act = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x): #Offset self attention.\n",
        "        # b, n, c\n",
        "        x_q = self.q_conv(x).permute(0, 2, 1)#kernal\n",
        "        # b, c, n\n",
        "        x_k = self.k_conv(x)# kernal \n",
        "        x_v = self.v_conv(x)# kernal\n",
        "        # b, n, n\n",
        "        energy = torch.bmm(x_q, x_k) #bmm is the simple batch matrix matrix multiply.matmul is more general as depending on the inputs, it can correspond to dot, mm or bmm.\n",
        "\n",
        "        attention = self.softmax(energy)\n",
        "        attention = attention / (1e-9 + attention.sum(dim=1, keepdim=True))\n",
        "        # b, c, n\n",
        "        x_r = torch.bmm(x_v, attention)\n",
        "        x_r = self.act(self.after_norm(self.trans_conv(x - x_r))) # L = D-E\n",
        "        x = x + x_r  \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANHNboKDCIc9"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51d8zV8J5bOA"
      },
      "source": [
        "### Train and validation with preset Train dataset and validation dataset, and  collect the train loss and accuracy rate as training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lyxlKopfOx7"
      },
      "source": [
        "def train_new(epochs=150, lr=0.0001):\n",
        "    result = pd.DataFrame(columns=['Epoch', 'train_loss', 'valid_acc', 'train_acc', 'valid_loss'])\n",
        "    train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True, drop_last=True)\n",
        "    test_loader = DataLoader(dataset=valid_ds, batch_size=5)\n",
        "    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    model = Pct().to(device)\n",
        "    print(str(model))\n",
        "    model = nn.DataParallel(model)\n",
        "    opt = optim.SGD(model.parameters(), lr=lr*100, momentum=0.9, weight_decay=5e-4)\n",
        "    \n",
        "    scheduler = CosineAnnealingLR(opt, epochs, lr)# SGD, lr,epoch as parameters.\n",
        "    \n",
        "    criterion = cal_loss\n",
        "    best_test_acc = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        scheduler.step()\n",
        "        train_loss = 0.0\n",
        "        count = 0.0\n",
        "        model.train()\n",
        "        train_pred = []\n",
        "        train_true = []\n",
        "        idx = 0 #epoch number\n",
        "        total_time = 0.0\n",
        "        for data, label in (train_loader):# train_loader has batch number difined, so it's batch training.\n",
        "            data, label = data.to(device).float(), label.to(device).squeeze()\n",
        "            #print(data.shape)\n",
        "            data = data.permute(0, 2, 1)# B,point number,point dimension (32, 500, 3) => (32,3,500)\n",
        "            batch_size = data.size()[0]\n",
        "            opt.zero_grad()# clear the previous gradiant.\n",
        "\n",
        "            start_time = time.time()\n",
        "            logits = model(data)#predicted y as logits.\n",
        "            loss = criterion(logits, label)#Calculate the loss\n",
        "            loss.backward()#Update weights.\n",
        "            opt.step() #SGD is adjusting learning rate for each batch.\n",
        "            end_time = time.time()\n",
        "            total_time += (end_time - start_time)\n",
        "            \n",
        "            # Get the max value from logits as preds.\n",
        "            #[[0.5, 0.5],\n",
        "            # [0.2, 0.8],\n",
        "            # [0.8, 0.2],\n",
        "            # ..........] \n",
        "            preds = logits.max(dim=1)[1] # get the final prediction through the max percentage.\n",
        "            count += batch_size# calculate the number of samples trained finally. sometimes final batch less than 32 will be dropped.\n",
        "            train_loss += loss.item() * batch_size # loss.item() is calculate the loss per sample.train loss is each sample times batch number then append every batch.\n",
        "            train_true.append(label.cpu().numpy())\n",
        "            train_pred.append(preds.detach().cpu().numpy()) # from GPU to CPU, from tensor to numpy as a list.\n",
        "            idx += 1\n",
        "            \n",
        "        print ('train total time is',total_time)\n",
        "        train_true = np.concatenate(train_true) # put all the ground truth to a list.\n",
        "        train_pred = np.concatenate(train_pred) # put all predicted label to a list\n",
        "        train_acc = metrics.accuracy_score(train_true, train_pred)# accuracy score.\n",
        "        avg_train_acc = metrics.balanced_accuracy_score(train_true, train_pred) # if the samples are not balanced,will have a balanced accuracy acore.\n",
        "        outstr = 'Train %d, loss: %.6f, train acc: %.6f, train avg acc: %.6f' % (epoch,\n",
        "                                                                                train_loss*1.0/count,\n",
        "                                                                                train_acc,\n",
        "                                                                                avg_train_acc)\n",
        "        print(outstr) \n",
        "\n",
        "        ####################\n",
        "        #    Validation   #\n",
        "        ####################\n",
        "        test_loss = 0.0\n",
        "        count = 0.0\n",
        "        model.eval() # not update the weight. but model.train() will update the weights.\n",
        "        test_pred = []\n",
        "        test_true = []\n",
        "        total_time = 0.0\n",
        "        for data, label in test_loader:\n",
        "            data, label = data.to(device).float(), label.to(device).squeeze() # float()(32byte long) is important here. The x, y, z coordinates of point cloud are double(2 8byte long).\n",
        "            data = data.permute(0, 2, 1)\n",
        "            batch_size = data.size()[0] #data.size( batch number, sample size(point number), sample dimentional information)\n",
        "            start_time = time.time() \n",
        "            logits = model(data)\n",
        "            end_time = time.time()\n",
        "            total_time += (end_time - start_time)\n",
        "            loss = criterion(logits, label)\n",
        "            preds = logits.max(dim=1)[1] \n",
        "            count += batch_size\n",
        "            test_loss += loss.item() * batch_size\n",
        "            test_true.append(label.cpu().numpy())\n",
        "            test_pred.append(preds.detach().cpu().numpy())\n",
        "        print ('test total time is', total_time)\n",
        "        test_true = np.concatenate(test_true) # concatente test_true for every batch\n",
        "        test_pred = np.concatenate(test_pred) # contatenat test_pred for every batch\n",
        "        test_acc = metrics.accuracy_score(test_true, test_pred)\n",
        "        avg_per_class_acc = metrics.balanced_accuracy_score(test_true, test_pred)\n",
        "        outstr = 'ValidEpoch-%d_loss-%.6f_testAcc-%.6f_testAvgAcc-%.6f' % (epoch,\n",
        "                                                                            test_loss*1.0/count,\n",
        "                                                                            test_acc,\n",
        "                                                                            avg_per_class_acc)\n",
        "        print(outstr)\n",
        "        result = result.append({\"Epoch\": epoch, \"train_loss\": train_loss*1.0/count, \"valid_acc\": avg_per_class_acc, 'train_acc': avg_train_acc, 'valid_loss': test_loss*1.0/count}, ignore_index=True)\n",
        "        if test_acc >= best_test_acc:\n",
        "            best_test_acc = test_acc\n",
        "            torch.save(model.state_dict(), 'gdrive/MyDrive/Capstone_606/PCT-models_150/model_%s.t7' % outstr)\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfb5Bzkw6PK-"
      },
      "source": [
        "### Put the training and validation to a dataframe and plot show. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KOz1dJryiCK",
        "outputId": "5de77e65-3375-4e5c-bb2f-bf81410d1144"
      },
      "source": [
        "train_valid_table = train_new()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pct(\n",
            "  (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "  (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (gather_local_0): Local_op(\n",
            "    (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (gather_local_1): Local_op(\n",
            "    (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (pt_last): Point_Transformer_Last(\n",
            "    (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (sa1): SA_Layer(\n",
            "      (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "      (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "      (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "      (softmax): Softmax(dim=-1)\n",
            "    )\n",
            "    (sa2): SA_Layer(\n",
            "      (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "      (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "      (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "      (softmax): Softmax(dim=-1)\n",
            "    )\n",
            "    (sa3): SA_Layer(\n",
            "      (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "      (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "      (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "      (softmax): Softmax(dim=-1)\n",
            "    )\n",
            "    (sa4): SA_Layer(\n",
            "      (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "      (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
            "      (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "      (softmax): Softmax(dim=-1)\n",
            "    )\n",
            "  )\n",
            "  (conv_fuse): Sequential(\n",
            "    (0): Conv1d(1280, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (linear1): Linear(in_features=1024, out_features=512, bias=False)\n",
            "  (bn6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dp1): Dropout(p=0.5, inplace=False)\n",
            "  (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (bn7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dp2): Dropout(p=0.5, inplace=False)\n",
            "  (linear3): Linear(in_features=256, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning:\n",
            "\n",
            "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train total time is 39.5653121471405\n",
            "Train 0, loss: 0.736853, train acc: 0.523897, train avg acc: 0.523898\n",
            "test total time is 1.768815040588379\n",
            "ValidEpoch-0_loss-0.698379_testAcc-0.612903_testAvgAcc-0.612903\n",
            "train total time is 39.55528521537781\n",
            "Train 1, loss: 0.731460, train acc: 0.534007, train avg acc: 0.534035\n",
            "test total time is 1.764366626739502\n",
            "ValidEpoch-1_loss-0.671115_testAcc-0.636201_testAvgAcc-0.636201\n",
            "train total time is 39.5643994808197\n",
            "Train 2, loss: 0.708829, train acc: 0.594669, train avg acc: 0.594686\n",
            "test total time is 1.7720422744750977\n",
            "ValidEpoch-2_loss-0.716931_testAcc-0.559140_testAvgAcc-0.559140\n",
            "train total time is 39.5610408782959\n",
            "Train 3, loss: 0.708931, train acc: 0.598805, train avg acc: 0.598805\n",
            "test total time is 1.7316584587097168\n",
            "ValidEpoch-3_loss-0.655330_testAcc-0.713262_testAvgAcc-0.713262\n",
            "train total time is 39.53766489028931\n",
            "Train 4, loss: 0.695419, train acc: 0.637868, train avg acc: 0.637839\n",
            "test total time is 1.7218501567840576\n",
            "ValidEpoch-4_loss-0.639355_testAcc-0.745520_testAvgAcc-0.745520\n",
            "train total time is 39.54354953765869\n",
            "Train 5, loss: 0.680061, train acc: 0.673713, train avg acc: 0.673713\n",
            "test total time is 1.6993968486785889\n",
            "ValidEpoch-5_loss-0.690936_testAcc-0.664875_testAvgAcc-0.664875\n",
            "train total time is 39.53946495056152\n",
            "Train 6, loss: 0.684765, train acc: 0.668199, train avg acc: 0.668208\n",
            "test total time is 1.7107431888580322\n",
            "ValidEpoch-6_loss-0.704369_testAcc-0.621864_testAvgAcc-0.621864\n",
            "train total time is 39.54344034194946\n",
            "Train 7, loss: 0.686486, train acc: 0.657629, train avg acc: 0.657619\n",
            "test total time is 1.7567574977874756\n",
            "ValidEpoch-7_loss-0.636149_testAcc-0.763441_testAvgAcc-0.763441\n",
            "train total time is 39.542235374450684\n",
            "Train 8, loss: 0.680159, train acc: 0.664982, train avg acc: 0.664991\n",
            "test total time is 1.7288684844970703\n",
            "ValidEpoch-8_loss-0.665187_testAcc-0.713262_testAvgAcc-0.713262\n",
            "train total time is 39.54823184013367\n",
            "Train 9, loss: 0.677095, train acc: 0.676471, train avg acc: 0.676483\n",
            "test total time is 1.7321829795837402\n",
            "ValidEpoch-9_loss-0.640460_testAcc-0.747312_testAvgAcc-0.747312\n",
            "train total time is 39.53669285774231\n",
            "Train 10, loss: 0.665714, train acc: 0.687500, train avg acc: 0.687472\n",
            "test total time is 1.7304813861846924\n",
            "ValidEpoch-10_loss-0.639673_testAcc-0.749104_testAvgAcc-0.749104\n",
            "train total time is 39.54745292663574\n",
            "Train 11, loss: 0.669305, train acc: 0.693934, train avg acc: 0.693896\n",
            "test total time is 1.7354216575622559\n",
            "ValidEpoch-11_loss-0.632906_testAcc-0.768817_testAvgAcc-0.768817\n",
            "train total time is 39.54853296279907\n",
            "Train 12, loss: 0.661815, train acc: 0.703125, train avg acc: 0.703122\n",
            "test total time is 1.7141311168670654\n",
            "ValidEpoch-12_loss-0.655698_testAcc-0.722222_testAvgAcc-0.722222\n",
            "train total time is 39.53463268280029\n",
            "Train 13, loss: 0.667985, train acc: 0.701287, train avg acc: 0.701265\n",
            "test total time is 1.7140192985534668\n",
            "ValidEpoch-13_loss-0.637292_testAcc-0.738351_testAvgAcc-0.738351\n",
            "train total time is 39.54184675216675\n",
            "Train 14, loss: 0.652631, train acc: 0.729320, train avg acc: 0.729327\n",
            "test total time is 1.7158210277557373\n",
            "ValidEpoch-14_loss-0.624136_testAcc-0.779570_testAvgAcc-0.779570\n",
            "train total time is 39.54187774658203\n",
            "Train 15, loss: 0.653509, train acc: 0.719669, train avg acc: 0.719669\n",
            "test total time is 1.7039449214935303\n",
            "ValidEpoch-15_loss-0.632911_testAcc-0.774194_testAvgAcc-0.774194\n",
            "train total time is 39.541200160980225\n",
            "Train 16, loss: 0.645930, train acc: 0.739890, train avg acc: 0.739886\n",
            "test total time is 1.716569423675537\n",
            "ValidEpoch-16_loss-0.611292_testAcc-0.797491_testAvgAcc-0.797491\n",
            "train total time is 39.54209494590759\n",
            "Train 17, loss: 0.641883, train acc: 0.747243, train avg acc: 0.747247\n",
            "test total time is 1.7206182479858398\n",
            "ValidEpoch-17_loss-0.608978_testAcc-0.801075_testAvgAcc-0.801075\n",
            "train total time is 39.54362750053406\n",
            "Train 18, loss: 0.645231, train acc: 0.744945, train avg acc: 0.744918\n",
            "test total time is 1.7184066772460938\n",
            "ValidEpoch-18_loss-0.633001_testAcc-0.783154_testAvgAcc-0.783154\n",
            "train total time is 39.53609347343445\n",
            "Train 19, loss: 0.650671, train acc: 0.739890, train avg acc: 0.739890\n",
            "test total time is 1.7224249839782715\n",
            "ValidEpoch-19_loss-0.618463_testAcc-0.811828_testAvgAcc-0.811828\n",
            "train total time is 39.54929566383362\n",
            "Train 20, loss: 0.642877, train acc: 0.753217, train avg acc: 0.753239\n",
            "test total time is 1.6959311962127686\n",
            "ValidEpoch-20_loss-0.608817_testAcc-0.811828_testAvgAcc-0.811828\n",
            "train total time is 39.52674460411072\n",
            "Train 21, loss: 0.641743, train acc: 0.751838, train avg acc: 0.751815\n",
            "test total time is 1.6987128257751465\n",
            "ValidEpoch-21_loss-0.630371_testAcc-0.784946_testAvgAcc-0.784946\n",
            "train total time is 39.53468608856201\n",
            "Train 22, loss: 0.633669, train acc: 0.774357, train avg acc: 0.774359\n",
            "test total time is 1.7391879558563232\n",
            "ValidEpoch-22_loss-0.616999_testAcc-0.808244_testAvgAcc-0.808244\n",
            "train total time is 39.53532695770264\n",
            "Train 23, loss: 0.635483, train acc: 0.774816, train avg acc: 0.774819\n",
            "test total time is 1.6948699951171875\n",
            "ValidEpoch-23_loss-0.609301_testAcc-0.815412_testAvgAcc-0.815412\n",
            "train total time is 39.53558897972107\n",
            "Train 24, loss: 0.627167, train acc: 0.772518, train avg acc: 0.772505\n",
            "test total time is 1.700373888015747\n",
            "ValidEpoch-24_loss-0.616200_testAcc-0.788530_testAvgAcc-0.788530\n",
            "train total time is 39.5325653553009\n",
            "Train 25, loss: 0.625671, train acc: 0.784007, train avg acc: 0.784030\n",
            "test total time is 1.6888439655303955\n",
            "ValidEpoch-25_loss-0.608222_testAcc-0.835125_testAvgAcc-0.835125\n",
            "train total time is 39.544026613235474\n",
            "Train 26, loss: 0.632175, train acc: 0.773438, train avg acc: 0.773432\n",
            "test total time is 1.7083992958068848\n",
            "ValidEpoch-26_loss-0.609194_testAcc-0.808244_testAvgAcc-0.808244\n",
            "train total time is 39.530972480773926\n",
            "Train 27, loss: 0.633838, train acc: 0.768842, train avg acc: 0.768854\n",
            "test total time is 1.7170417308807373\n",
            "ValidEpoch-27_loss-0.612242_testAcc-0.797491_testAvgAcc-0.797491\n",
            "train total time is 39.53053045272827\n",
            "Train 28, loss: 0.620675, train acc: 0.790441, train avg acc: 0.790453\n",
            "test total time is 1.7031950950622559\n",
            "ValidEpoch-28_loss-0.608623_testAcc-0.804659_testAvgAcc-0.804659\n",
            "train total time is 39.532451152801514\n",
            "Train 29, loss: 0.620590, train acc: 0.789062, train avg acc: 0.789053\n",
            "test total time is 1.7365853786468506\n",
            "ValidEpoch-29_loss-0.607117_testAcc-0.826165_testAvgAcc-0.826165\n",
            "train total time is 39.54347109794617\n",
            "Train 30, loss: 0.609781, train acc: 0.812960, train avg acc: 0.812943\n",
            "test total time is 1.7035470008850098\n",
            "ValidEpoch-30_loss-0.601130_testAcc-0.820789_testAvgAcc-0.820789\n",
            "train total time is 39.53254747390747\n",
            "Train 31, loss: 0.614974, train acc: 0.801011, train avg acc: 0.801021\n",
            "test total time is 1.7085332870483398\n",
            "ValidEpoch-31_loss-0.636307_testAcc-0.772401_testAvgAcc-0.772401\n",
            "train total time is 39.53438925743103\n",
            "Train 32, loss: 0.611914, train acc: 0.809283, train avg acc: 0.809304\n",
            "test total time is 1.6865005493164062\n",
            "ValidEpoch-32_loss-0.617540_testAcc-0.781362_testAvgAcc-0.781362\n",
            "train total time is 39.53358840942383\n",
            "Train 33, loss: 0.609230, train acc: 0.819853, train avg acc: 0.819853\n",
            "test total time is 1.7287626266479492\n",
            "ValidEpoch-33_loss-0.613352_testAcc-0.810036_testAvgAcc-0.810036\n",
            "train total time is 39.533900022506714\n",
            "Train 34, loss: 0.606801, train acc: 0.819393, train avg acc: 0.819345\n",
            "test total time is 1.7180376052856445\n",
            "ValidEpoch-34_loss-0.597096_testAcc-0.840502_testAvgAcc-0.840502\n",
            "train total time is 39.54316830635071\n",
            "Train 35, loss: 0.614177, train acc: 0.801930, train avg acc: 0.801970\n",
            "test total time is 1.7356712818145752\n",
            "ValidEpoch-35_loss-0.603713_testAcc-0.822581_testAvgAcc-0.822581\n",
            "train total time is 39.52269744873047\n",
            "Train 36, loss: 0.607244, train acc: 0.826746, train avg acc: 0.826765\n",
            "test total time is 1.7167673110961914\n",
            "ValidEpoch-36_loss-0.597105_testAcc-0.845878_testAvgAcc-0.845878\n",
            "train total time is 39.53908944129944\n",
            "Train 37, loss: 0.606382, train acc: 0.828125, train avg acc: 0.828148\n",
            "test total time is 1.7216029167175293\n",
            "ValidEpoch-37_loss-0.602597_testAcc-0.842294_testAvgAcc-0.842294\n",
            "train total time is 39.54079270362854\n",
            "Train 38, loss: 0.607955, train acc: 0.821232, train avg acc: 0.821259\n",
            "test total time is 1.726125955581665\n",
            "ValidEpoch-38_loss-0.609688_testAcc-0.818996_testAvgAcc-0.818996\n",
            "train total time is 39.53475904464722\n",
            "Train 39, loss: 0.609307, train acc: 0.818474, train avg acc: 0.818492\n",
            "test total time is 1.7232890129089355\n",
            "ValidEpoch-39_loss-0.605718_testAcc-0.831541_testAvgAcc-0.831541\n",
            "train total time is 39.54135203361511\n",
            "Train 40, loss: 0.597025, train acc: 0.844669, train avg acc: 0.844611\n",
            "test total time is 1.6951310634613037\n",
            "ValidEpoch-40_loss-0.586338_testAcc-0.862007_testAvgAcc-0.862007\n",
            "train total time is 39.532291412353516\n",
            "Train 41, loss: 0.590857, train acc: 0.852941, train avg acc: 0.852978\n",
            "test total time is 1.7003166675567627\n",
            "ValidEpoch-41_loss-0.593088_testAcc-0.838710_testAvgAcc-0.838710\n",
            "train total time is 39.5312123298645\n",
            "Train 42, loss: 0.592835, train acc: 0.848805, train avg acc: 0.848754\n",
            "test total time is 1.6948847770690918\n",
            "ValidEpoch-42_loss-0.583714_testAcc-0.878136_testAvgAcc-0.878136\n",
            "train total time is 39.52673006057739\n",
            "Train 43, loss: 0.596169, train acc: 0.843290, train avg acc: 0.843299\n",
            "test total time is 1.69038987159729\n",
            "ValidEpoch-43_loss-0.592545_testAcc-0.862007_testAvgAcc-0.862007\n",
            "train total time is 39.53272366523743\n",
            "Train 44, loss: 0.590610, train acc: 0.859835, train avg acc: 0.859893\n",
            "test total time is 1.6931476593017578\n",
            "ValidEpoch-44_loss-0.580745_testAcc-0.874552_testAvgAcc-0.874552\n",
            "train total time is 39.5267117023468\n",
            "Train 45, loss: 0.588808, train acc: 0.855239, train avg acc: 0.855275\n",
            "test total time is 1.6944806575775146\n",
            "ValidEpoch-45_loss-0.571927_testAcc-0.892473_testAvgAcc-0.892473\n",
            "train total time is 39.53211212158203\n",
            "Train 46, loss: 0.588903, train acc: 0.857996, train avg acc: 0.857981\n",
            "test total time is 1.6984918117523193\n",
            "ValidEpoch-46_loss-0.575170_testAcc-0.867384_testAvgAcc-0.867384\n",
            "train total time is 39.52878451347351\n",
            "Train 47, loss: 0.582052, train acc: 0.870864, train avg acc: 0.870842\n",
            "test total time is 1.6793923377990723\n",
            "ValidEpoch-47_loss-0.582213_testAcc-0.874552_testAvgAcc-0.874552\n",
            "train total time is 39.51921987533569\n",
            "Train 48, loss: 0.587412, train acc: 0.855239, train avg acc: 0.855216\n",
            "test total time is 1.7038285732269287\n",
            "ValidEpoch-48_loss-0.582180_testAcc-0.847670_testAvgAcc-0.847670\n",
            "train total time is 39.531776666641235\n",
            "Train 49, loss: 0.587425, train acc: 0.863511, train avg acc: 0.863415\n",
            "test total time is 1.7208836078643799\n",
            "ValidEpoch-49_loss-0.570273_testAcc-0.896057_testAvgAcc-0.896057\n",
            "train total time is 39.5248167514801\n",
            "Train 50, loss: 0.580443, train acc: 0.870404, train avg acc: 0.870420\n",
            "test total time is 1.6873528957366943\n",
            "ValidEpoch-50_loss-0.579455_testAcc-0.869176_testAvgAcc-0.869176\n",
            "train total time is 39.52478384971619\n",
            "Train 51, loss: 0.585470, train acc: 0.859835, train avg acc: 0.859803\n",
            "test total time is 1.7100775241851807\n",
            "ValidEpoch-51_loss-0.599727_testAcc-0.820789_testAvgAcc-0.820789\n",
            "train total time is 39.52350997924805\n",
            "Train 52, loss: 0.580108, train acc: 0.876379, train avg acc: 0.876405\n",
            "test total time is 1.7022078037261963\n",
            "ValidEpoch-52_loss-0.579705_testAcc-0.872760_testAvgAcc-0.872760\n",
            "train total time is 39.51750683784485\n",
            "Train 53, loss: 0.582742, train acc: 0.869485, train avg acc: 0.869565\n",
            "test total time is 1.6967556476593018\n",
            "ValidEpoch-53_loss-0.566484_testAcc-0.892473_testAvgAcc-0.892473\n",
            "train total time is 39.51896095275879\n",
            "Train 54, loss: 0.582767, train acc: 0.870404, train avg acc: 0.870404\n",
            "test total time is 1.69767165184021\n",
            "ValidEpoch-54_loss-0.568000_testAcc-0.910394_testAvgAcc-0.910394\n",
            "train total time is 39.51788115501404\n",
            "Train 55, loss: 0.578319, train acc: 0.881434, train avg acc: 0.881434\n",
            "test total time is 1.682861089706421\n",
            "ValidEpoch-55_loss-0.571069_testAcc-0.905018_testAvgAcc-0.905018\n",
            "train total time is 39.52673697471619\n",
            "Train 56, loss: 0.574862, train acc: 0.886029, train avg acc: 0.886066\n",
            "test total time is 1.6878490447998047\n",
            "ValidEpoch-56_loss-0.581535_testAcc-0.865591_testAvgAcc-0.865591\n",
            "train total time is 39.52616095542908\n",
            "Train 57, loss: 0.574364, train acc: 0.886949, train avg acc: 0.886959\n",
            "test total time is 1.6967501640319824\n",
            "ValidEpoch-57_loss-0.569546_testAcc-0.885305_testAvgAcc-0.885305\n",
            "train total time is 39.5388240814209\n",
            "Train 58, loss: 0.577584, train acc: 0.874540, train avg acc: 0.874527\n",
            "test total time is 1.7520103454589844\n",
            "ValidEpoch-58_loss-0.567255_testAcc-0.901434_testAvgAcc-0.901434\n",
            "train total time is 39.51834273338318\n",
            "Train 59, loss: 0.573449, train acc: 0.888327, train avg acc: 0.888327\n",
            "test total time is 1.6880528926849365\n",
            "ValidEpoch-59_loss-0.557974_testAcc-0.903226_testAvgAcc-0.903226\n",
            "train total time is 39.52535653114319\n",
            "Train 60, loss: 0.565413, train acc: 0.899816, train avg acc: 0.899841\n",
            "test total time is 1.6943442821502686\n",
            "ValidEpoch-60_loss-0.562556_testAcc-0.908602_testAvgAcc-0.908602\n",
            "train total time is 39.520509481430054\n",
            "Train 61, loss: 0.566311, train acc: 0.897978, train avg acc: 0.897974\n",
            "test total time is 1.6980834007263184\n",
            "ValidEpoch-61_loss-0.568707_testAcc-0.892473_testAvgAcc-0.892473\n",
            "train total time is 39.519880533218384\n",
            "Train 62, loss: 0.564616, train acc: 0.902114, train avg acc: 0.902095\n",
            "test total time is 1.6926994323730469\n",
            "ValidEpoch-62_loss-0.563488_testAcc-0.888889_testAvgAcc-0.888889\n",
            "train total time is 39.527037620544434\n",
            "Train 63, loss: 0.561262, train acc: 0.908548, train avg acc: 0.908523\n",
            "test total time is 1.7159552574157715\n",
            "ValidEpoch-63_loss-0.558133_testAcc-0.903226_testAvgAcc-0.903226\n",
            "train total time is 39.53002095222473\n",
            "Train 64, loss: 0.566127, train acc: 0.905331, train avg acc: 0.905317\n",
            "test total time is 1.6931004524230957\n",
            "ValidEpoch-64_loss-0.571274_testAcc-0.878136_testAvgAcc-0.878136\n",
            "train total time is 39.51637935638428\n",
            "Train 65, loss: 0.564620, train acc: 0.902574, train avg acc: 0.902574\n",
            "test total time is 1.717292070388794\n",
            "ValidEpoch-65_loss-0.547426_testAcc-0.933692_testAvgAcc-0.933692\n",
            "train total time is 39.51814818382263\n",
            "Train 66, loss: 0.558970, train acc: 0.910386, train avg acc: 0.910447\n",
            "test total time is 1.7041058540344238\n",
            "ValidEpoch-66_loss-0.553599_testAcc-0.922939_testAvgAcc-0.922939\n",
            "train total time is 39.51512694358826\n",
            "Train 67, loss: 0.568472, train acc: 0.898438, train avg acc: 0.898476\n",
            "test total time is 1.6832921504974365\n",
            "ValidEpoch-67_loss-0.572003_testAcc-0.862007_testAvgAcc-0.862007\n",
            "train total time is 39.51284861564636\n",
            "Train 68, loss: 0.563349, train acc: 0.907169, train avg acc: 0.907104\n",
            "test total time is 1.724161148071289\n",
            "ValidEpoch-68_loss-0.559982_testAcc-0.910394_testAvgAcc-0.910394\n",
            "train total time is 39.515807151794434\n",
            "Train 69, loss: 0.558129, train acc: 0.913143, train avg acc: 0.913109\n",
            "test total time is 1.6875615119934082\n",
            "ValidEpoch-69_loss-0.575340_testAcc-0.876344_testAvgAcc-0.876344\n",
            "train total time is 39.528055906295776\n",
            "Train 70, loss: 0.553389, train acc: 0.922794, train avg acc: 0.922745\n",
            "test total time is 1.68723464012146\n",
            "ValidEpoch-70_loss-0.562839_testAcc-0.901434_testAvgAcc-0.901434\n",
            "train total time is 39.5184588432312\n",
            "Train 71, loss: 0.561283, train acc: 0.906250, train avg acc: 0.906259\n",
            "test total time is 1.689751148223877\n",
            "ValidEpoch-71_loss-0.559059_testAcc-0.913978_testAvgAcc-0.913978\n",
            "train total time is 39.51882863044739\n",
            "Train 72, loss: 0.557787, train acc: 0.910386, train avg acc: 0.910373\n",
            "test total time is 1.712484359741211\n",
            "ValidEpoch-72_loss-0.555242_testAcc-0.919355_testAvgAcc-0.919355\n",
            "train total time is 39.52816987037659\n",
            "Train 73, loss: 0.554527, train acc: 0.922794, train avg acc: 0.922813\n",
            "test total time is 1.6966032981872559\n",
            "ValidEpoch-73_loss-0.565124_testAcc-0.899642_testAvgAcc-0.899642\n",
            "train total time is 39.529200315475464\n",
            "Train 74, loss: 0.550183, train acc: 0.930607, train avg acc: 0.930607\n",
            "test total time is 1.6915695667266846\n",
            "ValidEpoch-74_loss-0.552759_testAcc-0.917563_testAvgAcc-0.917563\n",
            "train total time is 39.5185809135437\n",
            "Train 75, loss: 0.553027, train acc: 0.923713, train avg acc: 0.923713\n",
            "test total time is 1.715198278427124\n",
            "ValidEpoch-75_loss-0.553363_testAcc-0.917563_testAvgAcc-0.917563\n",
            "train total time is 39.52394676208496\n",
            "Train 76, loss: 0.549835, train acc: 0.926930, train avg acc: 0.926857\n",
            "test total time is 1.7111949920654297\n",
            "ValidEpoch-76_loss-0.545293_testAcc-0.935484_testAvgAcc-0.935484\n",
            "train total time is 39.52150535583496\n",
            "Train 77, loss: 0.546185, train acc: 0.937960, train avg acc: 0.937951\n",
            "test total time is 1.7067160606384277\n",
            "ValidEpoch-77_loss-0.543864_testAcc-0.939068_testAvgAcc-0.939068\n",
            "train total time is 39.50926065444946\n",
            "Train 78, loss: 0.547673, train acc: 0.931985, train avg acc: 0.931985\n",
            "test total time is 1.6712708473205566\n",
            "ValidEpoch-78_loss-0.547433_testAcc-0.924731_testAvgAcc-0.924731\n",
            "train total time is 39.51974129676819\n",
            "Train 79, loss: 0.549732, train acc: 0.930607, train avg acc: 0.930595\n",
            "test total time is 1.688453197479248\n",
            "ValidEpoch-79_loss-0.551716_testAcc-0.921147_testAvgAcc-0.921147\n",
            "train total time is 39.512057065963745\n",
            "Train 80, loss: 0.547922, train acc: 0.932445, train avg acc: 0.932445\n",
            "test total time is 1.7379217147827148\n",
            "ValidEpoch-80_loss-0.542937_testAcc-0.937276_testAvgAcc-0.937276\n",
            "train total time is 39.51880860328674\n",
            "Train 81, loss: 0.543485, train acc: 0.941636, train avg acc: 0.941636\n",
            "test total time is 1.714756965637207\n",
            "ValidEpoch-81_loss-0.544629_testAcc-0.930108_testAvgAcc-0.930108\n",
            "train total time is 39.52347254753113\n",
            "Train 82, loss: 0.544283, train acc: 0.940717, train avg acc: 0.940704\n",
            "test total time is 1.680769920349121\n",
            "ValidEpoch-82_loss-0.548167_testAcc-0.922939_testAvgAcc-0.922939\n",
            "train total time is 39.5160608291626\n",
            "Train 83, loss: 0.547967, train acc: 0.928309, train avg acc: 0.928323\n",
            "test total time is 1.6744332313537598\n",
            "ValidEpoch-83_loss-0.557250_testAcc-0.917563_testAvgAcc-0.917563\n",
            "train total time is 39.52061986923218\n",
            "Train 84, loss: 0.546907, train acc: 0.934743, train avg acc: 0.934743\n",
            "test total time is 1.6928281784057617\n",
            "ValidEpoch-84_loss-0.547247_testAcc-0.933692_testAvgAcc-0.933692\n",
            "train total time is 39.514949560165405\n",
            "Train 85, loss: 0.538692, train acc: 0.951287, train avg acc: 0.951277\n",
            "test total time is 1.7039241790771484\n",
            "ValidEpoch-85_loss-0.532979_testAcc-0.951613_testAvgAcc-0.951613\n",
            "train total time is 39.524089336395264\n",
            "Train 86, loss: 0.540144, train acc: 0.952206, train avg acc: 0.952189\n",
            "test total time is 1.6934051513671875\n",
            "ValidEpoch-86_loss-0.537313_testAcc-0.955197_testAvgAcc-0.955197\n",
            "train total time is 39.526530027389526\n",
            "Train 87, loss: 0.540212, train acc: 0.947151, train avg acc: 0.947178\n",
            "test total time is 1.6914455890655518\n",
            "ValidEpoch-87_loss-0.543864_testAcc-0.930108_testAvgAcc-0.930108\n",
            "train total time is 39.52974534034729\n",
            "Train 88, loss: 0.540567, train acc: 0.947151, train avg acc: 0.947165\n",
            "test total time is 1.6920723915100098\n",
            "ValidEpoch-88_loss-0.541306_testAcc-0.948029_testAvgAcc-0.948029\n",
            "train total time is 39.524651288986206\n",
            "Train 89, loss: 0.540903, train acc: 0.949449, train avg acc: 0.949438\n",
            "test total time is 1.7023158073425293\n",
            "ValidEpoch-89_loss-0.547917_testAcc-0.930108_testAvgAcc-0.930108\n",
            "train total time is 39.51791167259216\n",
            "Train 90, loss: 0.535246, train acc: 0.954504, train avg acc: 0.954491\n",
            "test total time is 1.7156660556793213\n",
            "ValidEpoch-90_loss-0.531443_testAcc-0.951613_testAvgAcc-0.951613\n",
            "train total time is 39.50877785682678\n",
            "Train 91, loss: 0.539618, train acc: 0.943474, train avg acc: 0.943488\n",
            "test total time is 1.7005271911621094\n",
            "ValidEpoch-91_loss-0.538571_testAcc-0.942652_testAvgAcc-0.942652\n",
            "train total time is 39.51684594154358\n",
            "Train 92, loss: 0.537111, train acc: 0.952206, train avg acc: 0.952206\n",
            "test total time is 1.6834568977355957\n",
            "ValidEpoch-92_loss-0.537198_testAcc-0.948029_testAvgAcc-0.948029\n",
            "train total time is 39.51560568809509\n",
            "Train 93, loss: 0.535131, train acc: 0.948070, train avg acc: 0.948057\n",
            "test total time is 1.6751232147216797\n",
            "ValidEpoch-93_loss-0.540703_testAcc-0.940860_testAvgAcc-0.940860\n",
            "train total time is 39.512413024902344\n",
            "Train 94, loss: 0.532093, train acc: 0.962316, train avg acc: 0.962313\n",
            "test total time is 1.6966331005096436\n",
            "ValidEpoch-94_loss-0.533499_testAcc-0.956989_testAvgAcc-0.956989\n",
            "train total time is 39.513741970062256\n",
            "Train 95, loss: 0.535337, train acc: 0.951287, train avg acc: 0.951310\n",
            "test total time is 1.6784567832946777\n",
            "ValidEpoch-95_loss-0.530687_testAcc-0.956989_testAvgAcc-0.956989\n",
            "train total time is 39.52977657318115\n",
            "Train 96, loss: 0.536432, train acc: 0.957261, train avg acc: 0.957253\n",
            "test total time is 1.6830742359161377\n",
            "ValidEpoch-96_loss-0.529753_testAcc-0.960573_testAvgAcc-0.960573\n",
            "train total time is 39.51630234718323\n",
            "Train 97, loss: 0.531035, train acc: 0.964614, train avg acc: 0.964640\n",
            "test total time is 1.6830978393554688\n",
            "ValidEpoch-97_loss-0.533255_testAcc-0.962366_testAvgAcc-0.962366\n",
            "train total time is 39.52178978919983\n",
            "Train 98, loss: 0.537319, train acc: 0.950368, train avg acc: 0.950361\n",
            "test total time is 1.7018225193023682\n",
            "ValidEpoch-98_loss-0.542779_testAcc-0.940860_testAvgAcc-0.940860\n",
            "train total time is 39.523741006851196\n",
            "Train 99, loss: 0.531766, train acc: 0.960478, train avg acc: 0.960490\n",
            "test total time is 1.6871206760406494\n",
            "ValidEpoch-99_loss-0.533227_testAcc-0.951613_testAvgAcc-0.951613\n",
            "train total time is 39.51276254653931\n",
            "Train 100, loss: 0.530994, train acc: 0.962316, train avg acc: 0.962308\n",
            "test total time is 1.6971817016601562\n",
            "ValidEpoch-100_loss-0.532866_testAcc-0.948029_testAvgAcc-0.948029\n",
            "train total time is 39.51376175880432\n",
            "Train 101, loss: 0.532169, train acc: 0.957721, train avg acc: 0.957710\n",
            "test total time is 1.676572322845459\n",
            "ValidEpoch-101_loss-0.531137_testAcc-0.953405_testAvgAcc-0.953405\n",
            "train total time is 39.52427053451538\n",
            "Train 102, loss: 0.531487, train acc: 0.963695, train avg acc: 0.963683\n",
            "test total time is 1.6949176788330078\n",
            "ValidEpoch-102_loss-0.534038_testAcc-0.951613_testAvgAcc-0.951613\n",
            "train total time is 39.5125207901001\n",
            "Train 103, loss: 0.530044, train acc: 0.965533, train avg acc: 0.965507\n",
            "test total time is 1.6752657890319824\n",
            "ValidEpoch-103_loss-0.533033_testAcc-0.955197_testAvgAcc-0.955197\n",
            "train total time is 39.51962661743164\n",
            "Train 104, loss: 0.533012, train acc: 0.959559, train avg acc: 0.959559\n",
            "test total time is 1.6745693683624268\n",
            "ValidEpoch-104_loss-0.534109_testAcc-0.958781_testAvgAcc-0.958781\n",
            "train total time is 39.52192425727844\n",
            "Train 105, loss: 0.529523, train acc: 0.962776, train avg acc: 0.962769\n",
            "test total time is 1.6781859397888184\n",
            "ValidEpoch-105_loss-0.526987_testAcc-0.965950_testAvgAcc-0.965950\n",
            "train total time is 39.51573634147644\n",
            "Train 106, loss: 0.529890, train acc: 0.965533, train avg acc: 0.965525\n",
            "test total time is 1.6952214241027832\n",
            "ValidEpoch-106_loss-0.530191_testAcc-0.948029_testAvgAcc-0.948029\n",
            "train total time is 39.52102494239807\n",
            "Train 107, loss: 0.528914, train acc: 0.967371, train avg acc: 0.967388\n",
            "test total time is 1.6933038234710693\n",
            "ValidEpoch-107_loss-0.527738_testAcc-0.967742_testAvgAcc-0.967742\n",
            "train total time is 39.51957583427429\n",
            "Train 108, loss: 0.527760, train acc: 0.970588, train avg acc: 0.970595\n",
            "test total time is 1.700789451599121\n",
            "ValidEpoch-108_loss-0.526739_testAcc-0.960573_testAvgAcc-0.960573\n",
            "train total time is 39.52160716056824\n",
            "Train 109, loss: 0.529524, train acc: 0.965074, train avg acc: 0.965063\n",
            "test total time is 1.686833381652832\n",
            "ValidEpoch-109_loss-0.528563_testAcc-0.964158_testAvgAcc-0.964158\n",
            "train total time is 39.51120066642761\n",
            "Train 110, loss: 0.531309, train acc: 0.961397, train avg acc: 0.961390\n",
            "test total time is 1.6897060871124268\n",
            "ValidEpoch-110_loss-0.525339_testAcc-0.969534_testAvgAcc-0.969534\n",
            "train total time is 39.506139516830444\n",
            "Train 111, loss: 0.529328, train acc: 0.964614, train avg acc: 0.964608\n",
            "test total time is 1.7125132083892822\n",
            "ValidEpoch-111_loss-0.525306_testAcc-0.960573_testAvgAcc-0.960573\n",
            "train total time is 39.51608419418335\n",
            "Train 112, loss: 0.528425, train acc: 0.969210, train avg acc: 0.969231\n",
            "test total time is 1.7021307945251465\n",
            "ValidEpoch-112_loss-0.520442_testAcc-0.980287_testAvgAcc-0.980287\n",
            "train total time is 39.51152300834656\n",
            "Train 113, loss: 0.527602, train acc: 0.968290, train avg acc: 0.968276\n",
            "test total time is 1.7037019729614258\n",
            "ValidEpoch-113_loss-0.528870_testAcc-0.964158_testAvgAcc-0.964158\n",
            "train total time is 39.52184057235718\n",
            "Train 114, loss: 0.528737, train acc: 0.965993, train avg acc: 0.966001\n",
            "test total time is 1.697434425354004\n",
            "ValidEpoch-114_loss-0.524071_testAcc-0.967742_testAvgAcc-0.967742\n",
            "train total time is 39.52009296417236\n",
            "Train 115, loss: 0.525846, train acc: 0.970588, train avg acc: 0.970588\n",
            "test total time is 1.700843095779419\n",
            "ValidEpoch-115_loss-0.530361_testAcc-0.955197_testAvgAcc-0.955197\n",
            "train total time is 39.520912170410156\n",
            "Train 116, loss: 0.524598, train acc: 0.971967, train avg acc: 0.971967\n",
            "test total time is 1.6938536167144775\n",
            "ValidEpoch-116_loss-0.524316_testAcc-0.965950_testAvgAcc-0.965950\n",
            "train total time is 39.51407289505005\n",
            "Train 117, loss: 0.527592, train acc: 0.968750, train avg acc: 0.968758\n",
            "test total time is 1.6780409812927246\n",
            "ValidEpoch-117_loss-0.526032_testAcc-0.964158_testAvgAcc-0.964158\n",
            "train total time is 39.51745104789734\n",
            "Train 118, loss: 0.525604, train acc: 0.973805, train avg acc: 0.973807\n",
            "test total time is 1.6947665214538574\n",
            "ValidEpoch-118_loss-0.520558_testAcc-0.971326_testAvgAcc-0.971326\n",
            "train total time is 39.52150535583496\n",
            "Train 119, loss: 0.526265, train acc: 0.973346, train avg acc: 0.973362\n",
            "test total time is 1.6980786323547363\n",
            "ValidEpoch-119_loss-0.525141_testAcc-0.967742_testAvgAcc-0.967742\n",
            "train total time is 39.514615297317505\n",
            "Train 120, loss: 0.525341, train acc: 0.970129, train avg acc: 0.970135\n",
            "test total time is 1.6867992877960205\n",
            "ValidEpoch-120_loss-0.523713_testAcc-0.965950_testAvgAcc-0.965950\n",
            "train total time is 39.523324966430664\n",
            "Train 121, loss: 0.523367, train acc: 0.975184, train avg acc: 0.975184\n",
            "test total time is 1.681288480758667\n",
            "ValidEpoch-121_loss-0.522288_testAcc-0.973118_testAvgAcc-0.973118\n",
            "train total time is 39.516091108322144\n",
            "Train 122, loss: 0.525159, train acc: 0.972426, train avg acc: 0.972426\n",
            "test total time is 1.671377420425415\n",
            "ValidEpoch-122_loss-0.527901_testAcc-0.958781_testAvgAcc-0.958781\n",
            "train total time is 39.528478384017944\n",
            "Train 123, loss: 0.524076, train acc: 0.967831, train avg acc: 0.967808\n",
            "test total time is 1.7112348079681396\n",
            "ValidEpoch-123_loss-0.523358_testAcc-0.969534_testAvgAcc-0.969534\n",
            "train total time is 39.52416157722473\n",
            "Train 124, loss: 0.525582, train acc: 0.968750, train avg acc: 0.968750\n",
            "test total time is 1.6992826461791992\n",
            "ValidEpoch-124_loss-0.527051_testAcc-0.964158_testAvgAcc-0.964158\n",
            "train total time is 39.51209616661072\n",
            "Train 125, loss: 0.523280, train acc: 0.976562, train avg acc: 0.976566\n",
            "test total time is 1.6864783763885498\n",
            "ValidEpoch-125_loss-0.522106_testAcc-0.978495_testAvgAcc-0.978495\n",
            "train total time is 39.504974365234375\n",
            "Train 126, loss: 0.521466, train acc: 0.980239, train avg acc: 0.980255\n",
            "test total time is 1.6866202354431152\n",
            "ValidEpoch-126_loss-0.523473_testAcc-0.962366_testAvgAcc-0.962366\n",
            "train total time is 39.5114107131958\n",
            "Train 127, loss: 0.522715, train acc: 0.976103, train avg acc: 0.976113\n",
            "test total time is 1.684509038925171\n",
            "ValidEpoch-127_loss-0.530924_testAcc-0.949821_testAvgAcc-0.949821\n",
            "train total time is 39.50197744369507\n",
            "Train 128, loss: 0.519786, train acc: 0.981618, train avg acc: 0.981623\n",
            "test total time is 1.7034037113189697\n",
            "ValidEpoch-128_loss-0.527614_testAcc-0.960573_testAvgAcc-0.960573\n",
            "train total time is 39.52124881744385\n",
            "Train 129, loss: 0.525540, train acc: 0.969669, train avg acc: 0.969655\n",
            "test total time is 1.7055130004882812\n",
            "ValidEpoch-129_loss-0.522085_testAcc-0.965950_testAvgAcc-0.965950\n",
            "train total time is 39.50642466545105\n",
            "Train 130, loss: 0.522959, train acc: 0.980239, train avg acc: 0.980225\n",
            "test total time is 1.6768829822540283\n",
            "ValidEpoch-130_loss-0.522366_testAcc-0.978495_testAvgAcc-0.978495\n",
            "train total time is 39.511515378952026\n",
            "Train 131, loss: 0.521045, train acc: 0.977941, train avg acc: 0.977941\n",
            "test total time is 1.7055649757385254\n",
            "ValidEpoch-131_loss-0.523177_testAcc-0.969534_testAvgAcc-0.969534\n",
            "train total time is 39.51280355453491\n",
            "Train 132, loss: 0.525178, train acc: 0.972426, train avg acc: 0.972428\n",
            "test total time is 1.6781725883483887\n",
            "ValidEpoch-132_loss-0.523683_testAcc-0.969534_testAvgAcc-0.969534\n",
            "train total time is 39.50993227958679\n",
            "Train 133, loss: 0.521944, train acc: 0.977941, train avg acc: 0.977960\n",
            "test total time is 1.7003097534179688\n",
            "ValidEpoch-133_loss-0.525329_testAcc-0.967742_testAvgAcc-0.967742\n",
            "train total time is 39.513375997543335\n",
            "Train 134, loss: 0.522264, train acc: 0.979320, train avg acc: 0.979338\n",
            "test total time is 1.6655936241149902\n",
            "ValidEpoch-134_loss-0.521503_testAcc-0.974910_testAvgAcc-0.974910\n",
            "train total time is 39.51888990402222\n",
            "Train 135, loss: 0.524563, train acc: 0.974724, train avg acc: 0.974719\n",
            "test total time is 1.686537504196167\n",
            "ValidEpoch-135_loss-0.525062_testAcc-0.964158_testAvgAcc-0.964158\n",
            "train total time is 39.51146912574768\n",
            "Train 136, loss: 0.525241, train acc: 0.975184, train avg acc: 0.975184\n",
            "test total time is 1.6899023056030273\n",
            "ValidEpoch-136_loss-0.524794_testAcc-0.964158_testAvgAcc-0.964158\n",
            "train total time is 39.52092981338501\n",
            "Train 137, loss: 0.524176, train acc: 0.975184, train avg acc: 0.975184\n",
            "test total time is 1.680037260055542\n",
            "ValidEpoch-137_loss-0.523451_testAcc-0.965950_testAvgAcc-0.965950\n",
            "train total time is 39.52990460395813\n",
            "Train 138, loss: 0.523322, train acc: 0.977022, train avg acc: 0.977025\n",
            "test total time is 1.680910587310791\n",
            "ValidEpoch-138_loss-0.526689_testAcc-0.964158_testAvgAcc-0.964158\n",
            "train total time is 39.513402462005615\n",
            "Train 139, loss: 0.519720, train acc: 0.982996, train avg acc: 0.982996\n",
            "test total time is 1.7152643203735352\n",
            "ValidEpoch-139_loss-0.520050_testAcc-0.978495_testAvgAcc-0.978495\n",
            "train total time is 39.51300811767578\n",
            "Train 140, loss: 0.520329, train acc: 0.981618, train avg acc: 0.981618\n",
            "test total time is 1.6984596252441406\n",
            "ValidEpoch-140_loss-0.521484_testAcc-0.967742_testAvgAcc-0.967742\n",
            "train total time is 39.51879668235779\n",
            "Train 141, loss: 0.520192, train acc: 0.981618, train avg acc: 0.981618\n",
            "test total time is 1.6984891891479492\n",
            "ValidEpoch-141_loss-0.525537_testAcc-0.962366_testAvgAcc-0.962366\n",
            "train total time is 39.52157783508301\n",
            "Train 142, loss: 0.521927, train acc: 0.976103, train avg acc: 0.976093\n",
            "test total time is 1.6823844909667969\n",
            "ValidEpoch-142_loss-0.521008_testAcc-0.973118_testAvgAcc-0.973118\n",
            "train total time is 39.51364064216614\n",
            "Train 143, loss: 0.522987, train acc: 0.974265, train avg acc: 0.974282\n",
            "test total time is 1.6961100101470947\n",
            "ValidEpoch-143_loss-0.522150_testAcc-0.973118_testAvgAcc-0.973118\n",
            "train total time is 39.51707673072815\n",
            "Train 144, loss: 0.520584, train acc: 0.982996, train avg acc: 0.982993\n",
            "test total time is 1.6684019565582275\n",
            "ValidEpoch-144_loss-0.524804_testAcc-0.960573_testAvgAcc-0.960573\n",
            "train total time is 39.49411702156067\n",
            "Train 145, loss: 0.521727, train acc: 0.978401, train avg acc: 0.978409\n",
            "test total time is 1.6808218955993652\n",
            "ValidEpoch-145_loss-0.525738_testAcc-0.960573_testAvgAcc-0.960573\n",
            "train total time is 39.50757813453674\n",
            "Train 146, loss: 0.521626, train acc: 0.978860, train avg acc: 0.978865\n",
            "test total time is 1.695852279663086\n",
            "ValidEpoch-146_loss-0.523613_testAcc-0.965950_testAvgAcc-0.965950\n",
            "train total time is 39.510146617889404\n",
            "Train 147, loss: 0.520919, train acc: 0.981158, train avg acc: 0.981158\n",
            "test total time is 1.6929583549499512\n",
            "ValidEpoch-147_loss-0.520373_testAcc-0.969534_testAvgAcc-0.969534\n",
            "train total time is 39.51594948768616\n",
            "Train 148, loss: 0.521983, train acc: 0.980239, train avg acc: 0.980237\n",
            "test total time is 1.711850881576538\n",
            "ValidEpoch-148_loss-0.527211_testAcc-0.964158_testAvgAcc-0.964158\n",
            "train total time is 39.51694965362549\n",
            "Train 149, loss: 0.522902, train acc: 0.976103, train avg acc: 0.976103\n",
            "test total time is 1.6798181533813477\n",
            "ValidEpoch-149_loss-0.520447_testAcc-0.969534_testAvgAcc-0.969534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVqwOFiiCiks"
      },
      "source": [
        "### Validation accuracy and loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "FSSJKg1dnHh2",
        "outputId": "b3786ce9-5070-4a5a-8eb0-7f10b6ae744f"
      },
      "source": [
        "train_valid_table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_acc</th>\n",
              "      <th>train_acc</th>\n",
              "      <th>valid_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.873464</td>\n",
              "      <td>0.612903</td>\n",
              "      <td>0.523898</td>\n",
              "      <td>0.698379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.852431</td>\n",
              "      <td>0.636201</td>\n",
              "      <td>0.534035</td>\n",
              "      <td>0.671115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.764179</td>\n",
              "      <td>0.559140</td>\n",
              "      <td>0.594686</td>\n",
              "      <td>0.716931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.764576</td>\n",
              "      <td>0.713262</td>\n",
              "      <td>0.598805</td>\n",
              "      <td>0.655330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.711884</td>\n",
              "      <td>0.745520</td>\n",
              "      <td>0.637839</td>\n",
              "      <td>0.639355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>145.0</td>\n",
              "      <td>2.034547</td>\n",
              "      <td>0.960573</td>\n",
              "      <td>0.978409</td>\n",
              "      <td>0.525738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>146.0</td>\n",
              "      <td>2.034153</td>\n",
              "      <td>0.965950</td>\n",
              "      <td>0.978865</td>\n",
              "      <td>0.523613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>147.0</td>\n",
              "      <td>2.031396</td>\n",
              "      <td>0.969534</td>\n",
              "      <td>0.981158</td>\n",
              "      <td>0.520373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>148.0</td>\n",
              "      <td>2.035548</td>\n",
              "      <td>0.964158</td>\n",
              "      <td>0.980237</td>\n",
              "      <td>0.527211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>149.0</td>\n",
              "      <td>2.039129</td>\n",
              "      <td>0.969534</td>\n",
              "      <td>0.976103</td>\n",
              "      <td>0.520447</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Epoch  train_loss  valid_acc  train_acc  valid_loss\n",
              "0      0.0    2.873464   0.612903   0.523898    0.698379\n",
              "1      1.0    2.852431   0.636201   0.534035    0.671115\n",
              "2      2.0    2.764179   0.559140   0.594686    0.716931\n",
              "3      3.0    2.764576   0.713262   0.598805    0.655330\n",
              "4      4.0    2.711884   0.745520   0.637839    0.639355\n",
              "..     ...         ...        ...        ...         ...\n",
              "145  145.0    2.034547   0.960573   0.978409    0.525738\n",
              "146  146.0    2.034153   0.965950   0.978865    0.523613\n",
              "147  147.0    2.031396   0.969534   0.981158    0.520373\n",
              "148  148.0    2.035548   0.964158   0.980237    0.527211\n",
              "149  149.0    2.039129   0.969534   0.976103    0.520447\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hmQ9Wtn2X8H"
      },
      "source": [
        "train_valid_table.to_csv('/content/gdrive/MyDrive/Capstone_606/IntrA/generated/ad/train_valid_table_PCT_SGD_150.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "0eERBGbQo6sw",
        "outputId": "f5272996-fd0d-4062-b7c0-f6213fa99111"
      },
      "source": [
        "plt.plot(train_valid_table['Epoch'],train_valid_table['train_loss'])\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Loss function\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "bwnN02MCpIjf",
        "outputId": "b6acbca1-418c-4352-9fff-b8b5b394b3cd"
      },
      "source": [
        "plt.plot(train_valid_table['Epoch'],train_valid_table['valid_acc'])\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Valid Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbIJ7hHMTpiS"
      },
      "source": [
        "## Test the model with highest accuracy rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSATh3J-T504"
      },
      "source": [
        "#### Download the model which has highest validate accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_vsizmAm_T4"
      },
      "source": [
        "model_trained = \"/content/gdrive/MyDrive/Capstone_606/PCT-models_150/model_ValidEpoch-112_loss-0.520442_testAcc-0.980287_testAvgAcc-0.980287.t7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTRR9pF_UFYn"
      },
      "source": [
        "### Test with validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lajjNAxhykvq"
      },
      "source": [
        "def test_valid(model_path):\n",
        "    valid_roc = pd.DataFrame(columns=['label', 'pred', 'prob_0', 'prob_1'])\n",
        "    test_loader = DataLoader(dataset=valid_ds, batch_size=1)\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    model = Pct().to(device)\n",
        "    model = nn.DataParallel(model) \n",
        "    \n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model = model.eval()\n",
        "    test_true = []\n",
        "    test_pred = []\n",
        "\n",
        "    for data, label in test_loader:\n",
        "        data, label = data.to(device).float(), label.to(device).squeeze() # float() is important here. The x, y, z coordinates of point cloud are double.\n",
        "        data = data.permute(0, 2, 1)\n",
        "        logits = model(data)\n",
        "        #print(logits)\n",
        "        preds = logits.max(dim=1)[1] \n",
        "        # batch_size = 1\n",
        "        test_true.append([label.cpu().numpy()])\n",
        "        test_pred.append([preds.detach().cpu().numpy()])\n",
        "        #if args.test_batch_size == 1:\n",
        "        #    test_true.append([label.cpu().numpy()])\n",
        "        #    test_pred.append([preds.detach().cpu().numpy()])\n",
        "        #else:\n",
        "        #    test_true.append(label.cpu().numpy())\n",
        "        #    test_pred.append(preds.detach().cpu().numpy())\n",
        "        \n",
        "        valid_roc = valid_roc.append({\"label\": label.data.cpu().numpy(), \"pred\": preds.detach().cpu().numpy(), \n",
        "                                      \"prob_0\": math.exp(logits.data.cpu().numpy()[0][0]), \"prob_1\": math.exp(logits.data.cpu().numpy()[0][1])}, ignore_index=True)\n",
        "\n",
        "    test_true = np.concatenate(test_true)\n",
        "    test_pred = np.concatenate(test_pred)\n",
        "    test_acc = metrics.accuracy_score(test_true, test_pred)\n",
        "    avg_per_class_acc = metrics.balanced_accuracy_score(test_true, test_pred)\n",
        "    outstr = 'Test :: test acc: %.6f, test avg acc: %.6f'%(test_acc, avg_per_class_acc)\n",
        "    print(outstr)\n",
        "    return valid_roc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv7NbdRDpwa4",
        "outputId": "e58a2261-36d3-4971-aaed-53c286c6d397"
      },
      "source": [
        "valid_table = test_valid(model_trained)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test :: test acc: 0.964158, test avg acc: 0.964158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "wkybqhWDrM9u",
        "outputId": "29983cd4-8dfe-4bbe-8c07-d6baa21fa347"
      },
      "source": [
        "valid_table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "      <th>prob_0</th>\n",
              "      <th>prob_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>1.681266</td>\n",
              "      <td>0.444249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>1.970321</td>\n",
              "      <td>0.491032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>1.724078</td>\n",
              "      <td>0.482412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>1.584838</td>\n",
              "      <td>0.510387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>1.850644</td>\n",
              "      <td>0.413639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.329231</td>\n",
              "      <td>1.928845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.536564</td>\n",
              "      <td>1.435299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.475103</td>\n",
              "      <td>1.541288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.370817</td>\n",
              "      <td>1.767365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.711313</td>\n",
              "      <td>1.040566</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>558 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    label pred    prob_0    prob_1\n",
              "0       0  [0]  1.681266  0.444249\n",
              "1       0  [0]  1.970321  0.491032\n",
              "2       0  [0]  1.724078  0.482412\n",
              "3       0  [0]  1.584838  0.510387\n",
              "4       0  [0]  1.850644  0.413639\n",
              "..    ...  ...       ...       ...\n",
              "553     1  [1]  0.329231  1.928845\n",
              "554     1  [1]  0.536564  1.435299\n",
              "555     1  [1]  0.475103  1.541288\n",
              "556     1  [1]  0.370817  1.767365\n",
              "557     1  [1]  0.711313  1.040566\n",
              "\n",
              "[558 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6klsYZi9AU7"
      },
      "source": [
        "### Check the performance on testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqAW-JGr5-Fu"
      },
      "source": [
        "test_df = pd.read_csv('/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/test_df.csv')\n",
        "test_index_list = [test_df['Unnamed: 0'].tolist()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "oKsmZ43J6SwM",
        "outputId": "72ed581d-4217-43e5-ce02-ce11e7d0df77"
      },
      "source": [
        "test_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>Unnamed: 0.1.1.1</th>\n",
              "      <th>path</th>\n",
              "      <th>NumberPoint</th>\n",
              "      <th>classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1373</td>\n",
              "      <td>1373</td>\n",
              "      <td>1491</td>\n",
              "      <td>1491</td>\n",
              "      <td>/content/gdrive/My Drive/Capstone_606/IntrA/ge...</td>\n",
              "      <td>1633</td>\n",
              "      <td>vessel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>925</td>\n",
              "      <td>925</td>\n",
              "      <td>990</td>\n",
              "      <td>990</td>\n",
              "      <td>/content/gdrive/My Drive/Capstone_606/IntrA/ge...</td>\n",
              "      <td>1438</td>\n",
              "      <td>vessel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1470</td>\n",
              "      <td>1470</td>\n",
              "      <td>1600</td>\n",
              "      <td>1600</td>\n",
              "      <td>/content/gdrive/My Drive/Capstone_606/IntrA/ge...</td>\n",
              "      <td>687</td>\n",
              "      <td>vessel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1369</td>\n",
              "      <td>1369</td>\n",
              "      <td>1486</td>\n",
              "      <td>1486</td>\n",
              "      <td>/content/gdrive/My Drive/Capstone_606/IntrA/ge...</td>\n",
              "      <td>604</td>\n",
              "      <td>vessel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>858</td>\n",
              "      <td>858</td>\n",
              "      <td>921</td>\n",
              "      <td>921</td>\n",
              "      <td>/content/gdrive/My Drive/Capstone_606/IntrA/ge...</td>\n",
              "      <td>2383</td>\n",
              "      <td>vessel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>149</td>\n",
              "      <td>149</td>\n",
              "      <td>149</td>\n",
              "      <td>149</td>\n",
              "      <td>/content/gdrive/My Drive/Capstone_606/IntrA/ge...</td>\n",
              "      <td>1705</td>\n",
              "      <td>aneurysm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>/content/gdrive/My Drive/Capstone_606/IntrA/ge...</td>\n",
              "      <td>1026</td>\n",
              "      <td>aneurysm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>87</td>\n",
              "      <td>87</td>\n",
              "      <td>87</td>\n",
              "      <td>87</td>\n",
              "      <td>/content/gdrive/My Drive/Capstone_606/IntrA/ge...</td>\n",
              "      <td>944</td>\n",
              "      <td>aneurysm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>/content/gdrive/My Drive/Capstone_606/IntrA/ge...</td>\n",
              "      <td>1787</td>\n",
              "      <td>aneurysm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>/content/gdrive/My Drive/Capstone_606/IntrA/ge...</td>\n",
              "      <td>2435</td>\n",
              "      <td>aneurysm</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>174 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  Unnamed: 0.1  ...  NumberPoint  classification\n",
              "0          1373          1373  ...         1633          vessel\n",
              "1           925           925  ...         1438          vessel\n",
              "2          1470          1470  ...          687          vessel\n",
              "3          1369          1369  ...          604          vessel\n",
              "4           858           858  ...         2383          vessel\n",
              "..          ...           ...  ...          ...             ...\n",
              "169         149           149  ...         1705        aneurysm\n",
              "170         122           122  ...         1026        aneurysm\n",
              "171          87            87  ...          944        aneurysm\n",
              "172          70            70  ...         1787        aneurysm\n",
              "173          14            14  ...         2435        aneurysm\n",
              "\n",
              "[174 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1rvoT0x6bwf"
      },
      "source": [
        "class PointCloudDataTest(Dataset):\n",
        "    def __init__(self, df, valid=True, transform=default_transforms()):\n",
        "        self.classes = {\"vessel\": 0, \"aneurysm\": 1}\n",
        "        self.transforms = transform\n",
        "        self.valid = valid\n",
        "        self.files = df\n",
        "\n",
        "    def __len__(self):\n",
        "        print(self.files)\n",
        "        return len(self.files)\n",
        "\n",
        "    def __load_ad_file(self, path):\n",
        "        points = []\n",
        "        labels = []\n",
        "        normals = []\n",
        "        print(path)\n",
        "        with open(path, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                s_line = line.split()\n",
        "                points.append([float(s_line[0]), float(s_line[1]), float(s_line[2])])\n",
        "                normals.append([float(s_line[3]), float(s_line[4]), float(s_line[5])])\n",
        "                labels.append(int(s_line[6]))\n",
        "\n",
        "        return points, labels, normals\n",
        "        \n",
        "    def __preproc__(self, file):\n",
        "        points, labels, normals = self.__load_ad_file(file)\n",
        "        points = np.array(points)\n",
        "        if self.transforms:\n",
        "            pointcloud = self.transforms(points)\n",
        "        return pointcloud\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pcd_path = self.files.iloc[idx]['path']\n",
        "        category = self.files.iloc[idx]['classification']\n",
        "        \n",
        "        pointcloud = self.__preproc__(pcd_path)\n",
        "        return pointcloud, self.classes[category]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqG4eX9F6bzx"
      },
      "source": [
        "test_ds = PointCloudDataTest(test_df)\n",
        "test_loader = DataLoader(dataset=test_ds, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-FzwGT0Mhtk"
      },
      "source": [
        "def test_test(model_path):\n",
        "    test_roc = pd.DataFrame(columns=['label', 'pred', 'prob_0', 'prob_1'])\n",
        "    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    model = Pct().to(device)\n",
        "    model = nn.DataParallel(model) \n",
        "    \n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model = model.eval()\n",
        "    test_true = []\n",
        "    test_pred = []\n",
        "    with torch.no_grad():\n",
        "      for data, label in test_loader:\n",
        "          data, label = data.to(device).float(), label.to(device).squeeze() # float() is important here. The x, y, z coordinates of point cloud are double.\n",
        "          data = data.permute(0, 2, 1)\n",
        "          logits = model(data)\n",
        "          preds = logits.max(dim=1)[1] \n",
        "          # batch_size = 1\n",
        "          test_true.append([label.cpu().numpy()])\n",
        "          test_pred.append([preds.detach().cpu().numpy()])\n",
        "          #if args.test_batch_size == 1:\n",
        "          #    test_true.append([label.cpu().numpy()])\n",
        "          #    test_pred.append([preds.detach().cpu().numpy()])\n",
        "          #else:\n",
        "          #    test_true.append(label.cpu().numpy())\n",
        "          #    test_pred.append(preds.detach().cpu().numpy())\n",
        "          \n",
        "          test_roc = test_roc.append({\"label\": label.data.cpu().numpy(), \"pred\": preds.detach().cpu().numpy()[0], \n",
        "                                        \"prob_0\": nnf.softmax(logits, dim=1).data.cpu().numpy()[0][0], \"prob_1\": nnf.softmax(logits, dim=1).data.cpu().numpy()[0][1]}, ignore_index=True)\n",
        "\n",
        "    test_true = np.concatenate(test_true)\n",
        "    test_pred = np.concatenate(test_pred)\n",
        "    print(test_pred)\n",
        "    test_acc = metrics.accuracy_score(test_true, test_pred)\n",
        "    avg_per_class_acc = metrics.balanced_accuracy_score(test_true, test_pred)\n",
        "    outstr = 'Test :: test acc: %.6f, test avg acc: %.6f'%(test_acc, avg_per_class_acc)\n",
        "    print(outstr)\n",
        "    return test_roc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrtNft15_lAP",
        "outputId": "9864acb4-f1b3-4260-888e-5f07d53ac455"
      },
      "source": [
        "test_roc = test_test(model_trained)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Unnamed: 0  Unnamed: 0.1  ...  NumberPoint  classification\n",
            "0          1373          1373  ...         1633          vessel\n",
            "1           925           925  ...         1438          vessel\n",
            "2          1470          1470  ...          687          vessel\n",
            "3          1369          1369  ...          604          vessel\n",
            "4           858           858  ...         2383          vessel\n",
            "..          ...           ...  ...          ...             ...\n",
            "169         149           149  ...         1705        aneurysm\n",
            "170         122           122  ...         1026        aneurysm\n",
            "171          87            87  ...          944        aneurysm\n",
            "172          70            70  ...         1787        aneurysm\n",
            "173          14            14  ...         2435        aneurysm\n",
            "\n",
            "[174 rows x 7 columns]\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN212-19.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN182-0.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN219-15.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN212-14.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN177-0.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN19-15.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN211-7.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN32-15.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN3-12.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN217-10.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN119-3.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN42-12.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN26-7.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN135-2.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN158-19.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN155-3.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN23-2.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN158-10.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN116-11.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN155-7.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN204-18.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN193-6.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN213-9.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN174-1.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN190-2.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN200-15.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN119-19.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN183-13.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN42-8.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN40-4.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN120-3.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN178-18.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN187-8.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN139-15.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN153-5.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN58-13.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN209-4.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN121-1.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN160-0.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN138-11.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN3-9.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN182-3.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN144-19.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN6-7.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN157-5.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN25-19.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN137-1.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN137-9.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN157-15.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN116-3.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN187-0.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN25-0.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN204-15.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN213-12.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN173-5.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN171-4.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN216-7.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN186-9.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN58-9.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN205-9.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN209-0.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN175-15.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN190-1.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN3-4.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN203-11.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN204-3.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN129-18.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN183-16.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN192-9.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN134-7.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN205-3.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN140-15.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN193-7.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN174-13.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN181-3.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN207-1.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN6-12.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN31-7.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN175-3.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN196-13.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN205-4.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN207-4.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN168-19.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN161-3.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN191-14.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN55-1.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN3-5.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN157-2.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN214-7.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN148-9.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN149-9.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN142-0.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN186-12.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN186-15.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN175-2.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN129-14.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN148-0.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN1-0.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN152-11.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN54-18.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN119-17.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN129-11.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN171-18.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN1-7.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN173-1.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN116-6.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN136-4.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN55-6.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN9-4.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN186-4.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN172-15.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN128-8.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN58-11.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN197-12.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN218-6.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN196-6.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN3-1.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN167-3.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN28-8.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN209-11.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN193-13.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN181-4.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN1-14.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN196-9.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN44-19.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN121-17.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN121-18.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN166-1.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN34-5.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN214-15.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN155-19.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN19-13.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN217-14.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN192-5.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN31-17.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN196-8.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN3-8.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN210-7.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN206-4.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN125-19.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN208-6.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN216-14.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN200-6.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN188-15.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN191-9.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN128-10.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN200-1.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN160-15.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN215-0.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN207-13.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN149-1.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/vessel_ad/ArteryObjAN199-4.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN171-8_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN170-4_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN162-4_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN186-19_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN186-4_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN170-5_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN159-4_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN166-4_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN136-1_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN198-7_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN192-0_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN168-3_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN168-18_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN168-4_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN167-15_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN161-5_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN151-0_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN202-3_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN192-4_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN170-12_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN167-6_addon.ad\n",
            "/content/gdrive/My Drive/Capstone_606/IntrA/generated/ad/aneurysm_ad/ArteryObjAN153-0_addon.ad\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]]\n",
            "Test :: test acc: 0.867816, test avg acc: 0.807715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoLQidGFCyxd"
      },
      "source": [
        "### Roc Curve with test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "2y7wI4frSwt8",
        "outputId": "d86d4731-f864-4f2b-a28a-c5958549d382"
      },
      "source": [
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "#probs = model.predict_proba(X_test)\n",
        "#preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(test_roc['label'].astype(int), test_roc['prob_1'])\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import sklearn.metrics as metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n",
        "\n",
        "target_names = ['vessel 0', 'aneurysm 1']\n",
        "print(classification_report(test_roc['label'].astype(int), test_roc['pred'].astype(int), target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    vessel 0       0.96      0.89      0.92       152\n",
            "  aneurysm 1       0.48      0.73      0.58        22\n",
            "\n",
            "    accuracy                           0.87       174\n",
            "   macro avg       0.72      0.81      0.75       174\n",
            "weighted avg       0.90      0.87      0.88       174\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhwKmTbI1CUn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}